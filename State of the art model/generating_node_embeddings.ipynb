{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cudf as cdf\n",
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "import itertools as it\n",
    "import numpy as np\n",
    "import os"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load data and for merging and preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv('LI-Small_Trans.csv')\n",
    "df2 = pd.read_csv('HI-Small_Trans.csv')\n",
    "merged = pd.concat([df, df2])\n",
    "merged[\"Sending\"] = merged[\"From Bank\"].astype(str) + merged['Account']\n",
    "merged[\"Receiving\"] = merged[\"To Bank\"].astype(str) + merged['Account.1']\n",
    "processed = merged.drop(['From Bank', 'Account', 'To Bank', 'Account.1'], axis = 1)\n",
    "processed.to_csv(\"merged_processed.csv\")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Stratify Sample 1% of data and form training and test sets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "sample = merged.groupby('Is Laundering', group_keys= False).apply(lambda x:x.sample(frac = 0.01))\n",
    "sample.to_csv(\"sample_merged_processed.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = sample.drop(['Is Laundering'], axis = 1)\n",
    "y = sample[['Is Laundering']]\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size= 0.1, random_state= 100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train.to_csv(\"sample_X_train.csv\")\n",
    "y_train.to_csv(\"sample_y_train.csv\")\n",
    "X_test.to_csv(\"sample_X_test.csv\")\n",
    "y_test.to_csv(\"sample_y_test.csv\")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Get edge lists of both sets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def save_edges_to_csv(edge_list, name):\n",
    "    edge_frame = cdf.DataFrame(edge_list)\n",
    "    print(edge_frame)\n",
    "    no_dupes = edge_frame.drop_duplicates()\n",
    "    no_dupes.to_csv(name, index = False)\n",
    "    del no_dupes\n",
    "\n",
    "def get_in_common(X):\n",
    "    unique_sending = X['Sending'].unique()\n",
    "    unique_receiving = X['Receiving'].unique()\n",
    "    merged_unique = unique_sending.append(unique_receiving)\n",
    "    merged_unique = merged_unique.unique()\n",
    "    acct_nums = merged_unique.to_pandas()\n",
    "    res = []\n",
    "    for account_number in acct_nums:\n",
    "        in_common = X[(X['Sending'] == account_number) | (X['Receiving'] == account_number )].index.to_numpy()\n",
    "        res.append(in_common)\n",
    "    return res"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/root/miniconda3/envs/rapids-23.02/lib/python3.10/site-packages/cudf/core/indexed_frame.py:3424: FutureWarning: The append method is deprecated and will be removed in a future version. Use cudf.concat instead.\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "X_train = cdf.read_csv(\"sample_X_train.csv\")\n",
    "X_train_in_common = get_in_common(X_train)\n",
    "edges = []\n",
    "i = 0\n",
    "dump_num = 1\n",
    "for common in X_train_in_common:\n",
    "    n = len(common)\n",
    "    for i in range(0, n-1):\n",
    "        for j in range(i+1, n):\n",
    "            edges.append({'source' : common[i], 'target' : common[j]})\n",
    "            i = i + 1\n",
    "            if i > 15000000:\n",
    "                i = 0\n",
    "                save_edges_to_csv(edges, \"sample_X_train_edges-pt\" + str(dump_num))\n",
    "                dump_num = dump_num + 1\n",
    "                edges = []\n",
    "save_edges_to_csv(edges, \"sample_X_train_edges-pt\" + str(dump_num))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_test = cdf.read_csv(\"sample_X_test.csv\")\n",
    "X_test_in_common = get_in_common(X_test)\n",
    "edges = []\n",
    "i = 0\n",
    "dump_num = 1\n",
    "for common in X_train_in_common:\n",
    "    n = len(common)\n",
    "    for i in range(0, n-1):\n",
    "        for j in range(i+1, n):\n",
    "            edges.append({'source' : common[i], 'target' : common[j]})\n",
    "            i = i + 1\n",
    "            if i > 15000000:\n",
    "                i = 0\n",
    "                save_edges_to_csv(edges, \"sample_X_test_edges-pt\" + str(dump_num))\n",
    "                dump_num = dump_num + 1\n",
    "                edges = []\n",
    "save_edges_to_csv(edges, \"sample_X_test_edges-pt\" + str(dump_num))"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Use PecanPy to learn node embeddings of each transaction in each set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "os.system(\"pecanpy --input sample_X_train_edges-pt1 --output X_train_embeddings --mode SparseOTF --implicit_ids --delimiter ,\")\n",
    "os.system(\"pecanpy --input sample_X_test_edges-pt1 --output X_test_embeddings --mode SparseOTF --implicit_ids --delimiter ,\")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Combine embeddings with respective set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def combine_with_embeddings(train_file, embedding_file, target):\n",
    "    X = pd.read_csv(train_file)\n",
    "    embed = pd.read_csv(embedding_file, sep = \" \", header=None, index_col = 0, skiprows=1 )\n",
    "    X_embeddings = pd.merge(X, embed, left_index = True, right_index= True, how = \"left\").replace(np.nan, 0)\n",
    "    X_embeddings = X_embeddings.drop(columns = ['Unnamed: 0', 'Unnamed: 0.1', 'Timestamp', 'Sending', 'Receiving'])\n",
    "    X_embeddings.to_csv(target)\n",
    "    return X_embeddings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\User\\anaconda3\\lib\\site-packages\\IPython\\core\\interactiveshell.py:3357: DtypeWarning: Columns (0) have mixed types.Specify dtype option on import or set low_memory=False.\n",
      "  if (await self.run_code(code, result,  async_=asy)):\n"
     ]
    }
   ],
   "source": [
    "X_train_embeddings = combine_with_embeddings(\"sample_X_train.csv\", \"X_train_embeddings\", 'X_train_with_embeddings.csv')\n",
    "X_test_embeddings = combine_with_embeddings(\"sample_X_test.csv\", \"X_test_embeddings\", 'X_test_with_embeddings.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.10"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
